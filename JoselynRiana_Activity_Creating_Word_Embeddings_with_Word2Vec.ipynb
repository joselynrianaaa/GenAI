{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IxpvSXGD9nR",
        "outputId": "5345ecaa-997f-41fe-d362-d3c073c03ea3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample corpus\n",
        "corpus = [\n",
        "    \"Natural language processing is a fascinating field\",\n",
        "    \"Word embeddings capture semantic meanings\",\n",
        "    \"NLP is used in chatbots and virtual assistants\",\n",
        "    \"Word2Vec is a powerful tool for creating word embeddings\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "i5YPZC78EJow"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize sentences\n",
        "tokenized_corpus = [word_tokenize(sentence.lower()) for sentence in corpus]"
      ],
      "metadata": {
        "id": "JRsTG6ecEssX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Word2Vec model\n",
        "model = Word2Vec(sentences=tokenized_corpus, vector_size=100, window=5, min_count=1, workers=4)"
      ],
      "metadata": {
        "id": "bhZWadtCExBF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save(\"word2vec.model\")"
      ],
      "metadata": {
        "id": "Qz4W50OHE3eq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_words = model.wv.most_similar('nlp')\n",
        "print(similar_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0kkqtFzE7_Z",
        "outputId": "a7b930c8-db55-4fb9-bf60-058b885ba218"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('creating', 0.2528621256351471), ('natural', 0.14715638756752014), ('virtual', 0.14268764853477478), ('a', 0.13727159798145294), ('and', 0.11662642657756805), ('powerful', 0.07193466275930405), ('tool', 0.04568825289607048), ('for', 0.04409316927194595), ('used', 0.027098750695586205), ('language', 0.012944955378770828)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cwTLUzsVE-Eh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}